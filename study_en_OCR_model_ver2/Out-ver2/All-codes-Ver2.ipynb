{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9-xYSbcsqmJD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def read_images(input_folder):\n",
        "    \"\"\"\n",
        "    Reads all images from the input folder.\n",
        "\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "\n",
        "    Returns:\n",
        "    List of image file paths.\n",
        "    \"\"\"\n",
        "    image_files = []\n",
        "    for file in os.listdir(input_folder):\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            image_files.append(os.path.join(input_folder, file))\n",
        "    return image_files\n",
        "\n",
        "def draw_boxes(image, boxes, color=(0, 255, 0)):\n",
        "    for box in boxes:\n",
        "        if len(box) == 4:  # Ensuring box has the correct format\n",
        "            cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 2)\n",
        "    return image\n",
        "\n",
        "def save_image(output_folder, filename, image):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    Image.fromarray(image).save(os.path.join(output_folder, filename + '_highlighted.png'))\n",
        "\n",
        "def save_text(output_folder, filename, text):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    with open(os.path.join(output_folder, filename + '.txt'), 'w') as f:\n",
        "        f.write(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## easyocr_ocr"
      ],
      "metadata": {
        "id": "Jb3v163G2ARA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-bidi==0.4.2\n",
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Q1HmGVrZBh",
        "outputId": "e40c5aa5-c40c-400e-8292-28b4a2d3f90d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-bidi==0.4.2 in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi==0.4.2) (1.16.0)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.5)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.5.82)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wFmqV-pN1-II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "\n",
        "def easyocr_ocr(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Uses EasyOCR to read text from images in the input folder and save highlighted images and text in the output folder.\n",
        "\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "    output_folder (str): Path to the output folder to save highlighted images and text.\n",
        "    \"\"\"\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    image_files = read_images(input_folder)\n",
        "    for image_file in image_files:\n",
        "        image = cv2.imread(image_file)\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        easyocr_results = reader.readtext(image_rgb)\n",
        "        easyocr_boxes = []\n",
        "        text_content = \"\"\n",
        "        for result in easyocr_results:\n",
        "            box = result[0]\n",
        "            text = result[1]\n",
        "            confidence = result[2]\n",
        "            easyocr_boxes.append([int(min(point[0] for point in box)), int(min(point[1] for point in box)),\n",
        "                                  int(max(point[0] for point in box)), int(max(point[1] for point in box))])\n",
        "            text_content += f\"Text: {text}\\nConfidence: {confidence}\\n\\n\"\n",
        "\n",
        "        output_image = draw_boxes(image_rgb.copy(), easyocr_boxes, color=(0, 255, 0))  # Green\n",
        "        filename = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        save_image(output_folder, filename, output_image)\n",
        "        save_text(output_folder, filename, text_content)\n",
        "\n",
        "easyocr_ocr('/content/In', '/content/easyOCR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F75lTQIIrPP6",
        "outputId": "1364f293-5052-4647-dd90-fbe1afc01f09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tesseract-ocr"
      ],
      "metadata": {
        "id": "kYnfx2LJ162x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntMmhJCtt2su",
        "outputId": "a81852ca-2dae-4fa4-bcc3-1e3c27cc4f8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "\n",
        "def tesseract_ocr(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Uses Tesseract OCR to read text from images in the input folder and save highlighted images and text in the output folder.\n",
        "\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "    output_folder (str): Path to the output folder to save highlighted images and text.\n",
        "    \"\"\"\n",
        "    image_files = read_images(input_folder)\n",
        "    for image_file in image_files:\n",
        "        image = cv2.imread(image_file)\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        d = pytesseract.image_to_data(image_rgb, output_type=pytesseract.Output.DICT)\n",
        "        n_boxes = len(d['level'])\n",
        "        text_content = \"\"\n",
        "        tesseract_boxes = []\n",
        "\n",
        "        for i in range(n_boxes):\n",
        "            if int(d['conf'][i]) > 50:  # Confidence threshold\n",
        "                (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
        "                tesseract_boxes.append((x, y, x + w, y + h))\n",
        "                text_content += d['text'][i] + \" \"\n",
        "            if d['level'][i] == 5:  # End of a paragraph\n",
        "                text_content += \"\\n\"\n",
        "\n",
        "        output_image = draw_boxes(image_rgb.copy(), tesseract_boxes, color=(255, 0, 0))  # Red\n",
        "        filename = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        save_image(output_folder, filename, output_image)\n",
        "        save_text(output_folder, filename, text_content.strip())\n",
        "\n",
        "tesseract_ocr('/content/In', '/content/pytesseract')\n"
      ],
      "metadata": {
        "id": "8ie4xA0Atzxl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paddle OCR"
      ],
      "metadata": {
        "id": "ZvtGHgcb13eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install paddlepaddle paddleocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsfoEeRx0Ld",
        "outputId": "18514de4-e190-4880-c33f-b273abe18a36"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: paddleocr in /usr/local/lib/python3.10/dist-packages (2.8.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (9.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.20.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from paddleocr) (2.0.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.19.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.4.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.3.0.post5)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.66.4)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from paddleocr) (3.9.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.8.0.76)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.8.0.76)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from paddleocr) (3.0.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from paddleocr) (6.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from paddleocr) (1.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.12.3)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (4.53.1)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from paddleocr) (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from paddleocr) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->paddleocr) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->paddleocr) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->paddleocr) (2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (3.7.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->paddleocr) (2.31.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (3.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->paddleocr) (24.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->paddleocr) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->paddleocr) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->paddleocr) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle) (1.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->paddleocr) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from paddleocr import PaddleOCR\n",
        "\n",
        "\n",
        "def paddleocr_ocr(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Uses PaddleOCR to read text from images in the input folder and save highlighted images and text in the output folder.\n",
        "\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "    output_folder (str): Path to the output folder to save highlighted images and text.\n",
        "    \"\"\"\n",
        "    ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "    image_files = read_images(input_folder)\n",
        "    for image_file in image_files:\n",
        "        image = cv2.imread(image_file)\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        paddleocr_results = ocr.ocr(image_file, cls=True)\n",
        "        paddleocr_boxes = []\n",
        "        text_content = \"\"\n",
        "\n",
        "        for result in paddleocr_results:\n",
        "            for line in result:\n",
        "                box = line[0]\n",
        "                text = line[1][0]\n",
        "                confidence = line[1][1]\n",
        "                paddleocr_boxes.append([int(min(point[0] for point in box)), int(min(point[1] for point in box)),\n",
        "                                        int(max(point[0] for point in box)), int(max(point[1] for point in box))])\n",
        "                text_content += f\"Text: {text}, Confidence: {confidence:.2f}\\n\"\n",
        "\n",
        "        output_image = draw_boxes(image_rgb.copy(), paddleocr_boxes, color=(0, 0, 255))  # Blue\n",
        "        filename = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        save_image(output_folder, filename, output_image)\n",
        "        save_text(output_folder, filename, text_content.strip())\n",
        "\n",
        "paddleocr_ocr('/content/In', '/content/PaddleOCR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSFY1oBBuqrN",
        "outputId": "a2c206ad-130c-4484-b9e4-834532b1b6cf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.00M/4.00M [00:16<00:00, 245kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.2M/10.2M [00:18<00:00, 545kiB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.19M/2.19M [00:14<00:00, 146kiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024/07/23 04:11:35] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024/07/23 04:11:37] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.5579695701599121\n",
            "[2024/07/23 04:11:37] ppocr DEBUG: cls num  : 6, elapsed : 0.059670448303222656\n",
            "[2024/07/23 04:11:38] ppocr DEBUG: rec_res num  : 6, elapsed : 0.5014560222625732\n",
            "[2024/07/23 04:11:39] ppocr DEBUG: dt_boxes num : 19, elapsed : 0.7585844993591309\n",
            "[2024/07/23 04:11:39] ppocr DEBUG: cls num  : 19, elapsed : 0.07429313659667969\n",
            "[2024/07/23 04:11:52] ppocr DEBUG: rec_res num  : 19, elapsed : 13.349321842193604\n",
            "[2024/07/23 04:11:53] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.3621659278869629\n",
            "[2024/07/23 04:11:53] ppocr DEBUG: cls num  : 12, elapsed : 0.031041860580444336\n",
            "[2024/07/23 04:11:54] ppocr DEBUG: rec_res num  : 12, elapsed : 1.0566926002502441\n",
            "[2024/07/23 04:11:55] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.3707089424133301\n",
            "[2024/07/23 04:11:55] ppocr DEBUG: cls num  : 4, elapsed : 0.03740119934082031\n",
            "[2024/07/23 04:11:55] ppocr DEBUG: rec_res num  : 4, elapsed : 0.39806628227233887\n",
            "[2024/07/23 04:11:56] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.2738149166107178\n",
            "[2024/07/23 04:11:56] ppocr DEBUG: cls num  : 16, elapsed : 0.04488062858581543\n",
            "[2024/07/23 04:11:58] ppocr DEBUG: rec_res num  : 16, elapsed : 2.3920302391052246\n",
            "[2024/07/23 04:11:59] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.294161319732666\n",
            "[2024/07/23 04:11:59] ppocr DEBUG: cls num  : 8, elapsed : 0.0548405647277832\n",
            "[2024/07/23 04:11:59] ppocr DEBUG: rec_res num  : 8, elapsed : 0.7291605472564697\n",
            "[2024/07/23 04:12:00] ppocr DEBUG: dt_boxes num : 9, elapsed : 0.35669779777526855\n",
            "[2024/07/23 04:12:01] ppocr DEBUG: cls num  : 9, elapsed : 0.06538844108581543\n",
            "[2024/07/23 04:12:01] ppocr DEBUG: rec_res num  : 9, elapsed : 0.6008405685424805\n",
            "[2024/07/23 04:12:06] ppocr DEBUG: dt_boxes num : 30, elapsed : 0.29349493980407715\n",
            "[2024/07/23 04:12:06] ppocr DEBUG: cls num  : 30, elapsed : 0.08434033393859863\n",
            "[2024/07/23 04:12:08] ppocr DEBUG: rec_res num  : 30, elapsed : 1.7852647304534912\n",
            "[2024/07/23 04:12:08] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.35152435302734375\n",
            "[2024/07/23 04:12:08] ppocr DEBUG: cls num  : 16, elapsed : 0.08411812782287598\n",
            "[2024/07/23 04:12:11] ppocr DEBUG: rec_res num  : 16, elapsed : 2.9213805198669434\n",
            "[2024/07/23 04:12:12] ppocr DEBUG: dt_boxes num : 28, elapsed : 0.23288202285766602\n",
            "[2024/07/23 04:12:12] ppocr DEBUG: cls num  : 28, elapsed : 0.08095407485961914\n",
            "[2024/07/23 04:12:13] ppocr DEBUG: rec_res num  : 28, elapsed : 1.5115406513214111\n",
            "[2024/07/23 04:12:14] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.3211662769317627\n",
            "[2024/07/23 04:12:14] ppocr DEBUG: cls num  : 6, elapsed : 0.016294479370117188\n",
            "[2024/07/23 04:12:15] ppocr DEBUG: rec_res num  : 6, elapsed : 0.7428357601165771\n",
            "[2024/07/23 04:12:15] ppocr DEBUG: dt_boxes num : 9, elapsed : 0.2479994297027588\n",
            "[2024/07/23 04:12:15] ppocr DEBUG: cls num  : 9, elapsed : 0.03467845916748047\n",
            "[2024/07/23 04:12:17] ppocr DEBUG: rec_res num  : 9, elapsed : 1.650618314743042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##pytesseract with opencv prep"
      ],
      "metadata": {
        "id": "BwQEQexj1wF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "\n",
        "def preprocess_and_tesseract_ocr(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Preprocess images using OpenCV and uses Tesseract OCR to read text from images in the input folder and save highlighted images and text in the output folder.\n",
        "\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "    output_folder (str): Path to the output folder to save highlighted images and text.\n",
        "    \"\"\"\n",
        "    image_files = read_images(input_folder)\n",
        "    for image_file in image_files:\n",
        "        image = cv2.imread(image_file)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "        _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Use Tesseract with confidence level output\n",
        "        tesseract_data = pytesseract.image_to_data(binary, output_type=pytesseract.Output.DICT)\n",
        "        tesseract_boxes = []\n",
        "        text_content = \"\"\n",
        "\n",
        "        for i in range(len(tesseract_data['level'])):\n",
        "            (x, y, w, h, text, conf) = (tesseract_data['left'][i], tesseract_data['top'][i],\n",
        "                                        tesseract_data['width'][i], tesseract_data['height'][i],\n",
        "                                        tesseract_data['text'][i], tesseract_data['conf'][i])\n",
        "            if conf != '-1':\n",
        "                tesseract_boxes.append((x, y, x + w, y + h))\n",
        "                text_content += f\"Text: {text}, Confidence: {conf}\\n\"\n",
        "\n",
        "        output_image = draw_boxes(cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB), tesseract_boxes, color=(255, 0, 0))  # Red\n",
        "        filename = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        save_image(output_folder, filename, output_image)\n",
        "        save_text(output_folder, filename, text_content.strip())\n",
        "\n",
        "preprocess_and_tesseract_ocr('/content/In', '/content/pytesseract_opncv')"
      ],
      "metadata": {
        "id": "Saw5G2710dDD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## keras_ocr"
      ],
      "metadata": {
        "id": "bs4yqfnv1tYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9fl448V1I_C",
        "outputId": "d8d0916e-44fe-4c58-fe8a-45ca21de9942"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_ocr\n",
            "  Downloading keras_ocr-0.9.3-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (0.6.2)\n",
            "Collecting efficientnet==1.0.0 (from keras_ocr)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting essential_generators (from keras_ocr)\n",
            "  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (4.53.1)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (0.4.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (1.3.0.post5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (2.0.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (4.66.4)\n",
            "Collecting validators (from keras_ocr)\n",
            "  Downloading validators-0.33.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras_ocr)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras_ocr) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (2.31.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras_ocr) (3.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (3.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (2.8.2)\n",
            "Installing collected packages: essential_generators, validators, keras-applications, efficientnet, keras_ocr\n",
            "Successfully installed efficientnet-1.0.0 essential_generators-1.0 keras-applications-1.0.8 keras_ocr-0.9.3 validators-0.33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras_ocr\n",
        "\n",
        "def read_images(input_folder):\n",
        "    \"\"\"\n",
        "    Reads all images from the input folder.\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "    Returns:\n",
        "    List of image file paths.\n",
        "    \"\"\"\n",
        "    image_files = []\n",
        "    for file in os.listdir(input_folder):\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            image_files.append(os.path.join(input_folder, file))\n",
        "    return image_files\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Preprocess the image to improve OCR results.\n",
        "    Args:\n",
        "    image (numpy array): The input image.\n",
        "    Returns:\n",
        "    numpy array: The preprocessed image.\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    resized = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "    processed_image = cv2.adaptiveThreshold(resized, 255,\n",
        "                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                            cv2.THRESH_BINARY, 31, 2)\n",
        "    # Convert back to a 3-channel image\n",
        "    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)\n",
        "    return processed_image\n",
        "\n",
        "def draw_boxes(image, boxes, color=(0, 255, 0)):\n",
        "    for box in boxes:\n",
        "        if len(box) == 4:  # Ensuring box has the correct format\n",
        "            cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 2)\n",
        "    return image\n",
        "\n",
        "def save_image(output_folder, filename, image):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    Image.fromarray(image).save(os.path.join(output_folder, filename + '_highlighted.png'))\n",
        "\n",
        "def save_text(output_folder, filename, text):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    with open(os.path.join(output_folder, filename + '.txt'), 'w') as f:\n",
        "        f.write(text)\n",
        "\n",
        "def keras_ocr_function(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Uses Keras-OCR to read text from images in the input folder and save highlighted images in the output folder.\n",
        "    Args:\n",
        "    input_folder (str): Path to the input folder containing images.\n",
        "    output_folder (str): Path to the output folder to save highlighted images.\n",
        "    \"\"\"\n",
        "    pipeline = keras_ocr.pipeline.Pipeline()\n",
        "    image_files = read_images(input_folder)\n",
        "    for image_file in image_files:\n",
        "        image = keras_ocr.tools.read(image_file)\n",
        "        preprocessed_image = preprocess_image(image)\n",
        "        predictions = pipeline.recognize([preprocessed_image])[0]\n",
        "        boxes = []\n",
        "        text_with_confidence = []\n",
        "\n",
        "        for prediction in predictions:\n",
        "            text = prediction[0]\n",
        "            box = prediction[1]\n",
        "            text_with_confidence.append(f\"{text}\")\n",
        "\n",
        "            x1, y1 = int(box[0][0]), int(box[0][1])\n",
        "            x2, y2 = int(box[2][0]), int(box[2][1])\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "        output_image = draw_boxes(preprocessed_image.copy(), boxes, color=(0, 255, 0))  # Green\n",
        "        filename = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        save_image(output_folder, filename, output_image)\n",
        "        save_text(output_folder, filename, \"\\n\".join(text_with_confidence))\n",
        "\n",
        "# Usage example:\n",
        "keras_ocr_function('/content/In', 'Keras_ocr')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrITkM_u1HVa",
        "outputId": "2131eb30-c4c5-4700-ff41-4dea96678533"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Looking for /root/.keras-ocr/crnn_kurapan.h5\n",
            "1/1 [==============================] - 40s 40s/step\n",
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x794b2e49c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 53s 53s/step\n",
            "7/7 [==============================] - 55s 8s/step\n",
            "1/1 [==============================] - 52s 52s/step\n",
            "2/2 [==============================] - 8s 259ms/step\n",
            "1/1 [==============================] - 51s 51s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 50s 50s/step\n",
            "14/14 [==============================] - 120s 8s/step\n",
            "1/1 [==============================] - 41s 41s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 50s 50s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 49s 49s/step\n",
            "3/3 [==============================] - 21s 6s/step\n",
            "1/1 [==============================] - 44s 44s/step\n",
            "2/2 [==============================] - 16s 8s/step\n",
            "1/1 [==============================] - 39s 39s/step\n",
            "2/2 [==============================] - 14s 5s/step\n",
            "1/1 [==============================] - 38s 38s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 31s 31s/step\n",
            "2/2 [==============================] - 16s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r Keras_ocr.zip /content/Keras_ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XleMR_cL3Yqp",
        "outputId": "4027c10e-ccf7-4504-9f59-f8480d9db7fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Keras_ocr/ (stored 0%)\n",
            "  adding: content/Keras_ocr/12.txt (deflated 49%)\n",
            "  adding: content/Keras_ocr/5.txt (deflated 31%)\n",
            "  adding: content/Keras_ocr/4_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/10.txt (deflated 43%)\n",
            "  adding: content/Keras_ocr/7.txt (deflated 27%)\n",
            "  adding: content/Keras_ocr/2.txt (deflated 38%)\n",
            "  adding: content/Keras_ocr/8.txt (deflated 4%)\n",
            "  adding: content/Keras_ocr/12_highlighted.png (deflated 12%)\n",
            "  adding: content/Keras_ocr/6_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/9.txt (deflated 8%)\n",
            "  adding: content/Keras_ocr/6.txt (deflated 36%)\n",
            "  adding: content/Keras_ocr/3.txt (deflated 26%)\n",
            "  adding: content/Keras_ocr/7_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/4.txt (deflated 35%)\n",
            "  adding: content/Keras_ocr/11.txt (deflated 47%)\n",
            "  adding: content/Keras_ocr/8_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/1_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/11_highlighted.png (deflated 2%)\n",
            "  adding: content/Keras_ocr/10_highlighted.png (deflated 1%)\n",
            "  adding: content/Keras_ocr/5_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/2_highlighted.png (deflated 2%)\n",
            "  adding: content/Keras_ocr/1.txt (deflated 3%)\n",
            "  adding: content/Keras_ocr/9_highlighted.png (deflated 0%)\n",
            "  adding: content/Keras_ocr/3_highlighted.png (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from doctr.io import DocumentFile\n",
        "from doctr.models import ocr_predictor\n",
        "\n",
        "def read_images(input_folder):\n",
        "    \"\"\"\n",
        "    Reads image files from the specified input folder.\n",
        "    Args:\n",
        "    input_folder (str): Path to the folder containing the input images.\n",
        "    Returns:\n",
        "    list: A list of file paths for the images in the input folder.\n",
        "    \"\"\"\n",
        "    image_files = []\n",
        "    for file in os.listdir(input_folder):\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Ensure we read only image files\n",
        "            image_files.append(os.path.join(input_folder, file))\n",
        "    return image_files\n",
        "\n",
        "def save_image(output_folder, filename, image):\n",
        "    \"\"\"\n",
        "    Saves the image to the specified output folder.\n",
        "    Args:\n",
        "    output_folder (str): Path to the folder where the image will be saved.\n",
        "    filename (str): The name of the file to save the image as.\n",
        "    image (numpy.ndarray): The image to save.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    output_path = os.path.join(output_folder, f\"{filename}.png\")\n",
        "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "def perform_ocr_doctr(image_path):\n",
        "    \"\"\"\n",
        "    Performs OCR on the image using the doctr library.\n",
        "    Args:\n",
        "    image_path (str): Path to the image file.\n",
        "    Returns:\n",
        "    Document: The OCR result as a doctr Document object.\n",
        "    \"\"\"\n",
        "    model = ocr_predictor(pretrained=True)\n",
        "    doc = DocumentFile.from_images(image_path)\n",
        "    result = model(doc)\n",
        "    return result\n",
        "\n",
        "def draw_boxes(image_path, result):\n",
        "    \"\"\"\n",
        "    Draws bounding boxes around the recognized text in the image.\n",
        "    Args:\n",
        "    image_path (str): Path to the image file.\n",
        "    result (Document): The OCR result as a doctr Document object.\n",
        "    Returns:\n",
        "    numpy.ndarray: The image with bounding boxes drawn around recognized text.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "    for page in result.pages:\n",
        "        for block in page.blocks:\n",
        "            for line in block.lines:\n",
        "                for word in line.words:\n",
        "                    # Extract bounding box coordinates\n",
        "                    (x_min, y_min), (x_max, y_max) = word.geometry\n",
        "                    # Convert normalized coordinates to pixel coordinates\n",
        "                    box = [\n",
        "                        int(x_min * width), int(y_min * height),\n",
        "                        int(x_max * width), int(y_max * height)\n",
        "                    ]\n",
        "                    # Draw rectangle on the image\n",
        "                    cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "    return image\n",
        "\n",
        "def extract_text(result):\n",
        "    \"\"\"\n",
        "    Extracts text content from the OCR result.\n",
        "    Args:\n",
        "    result (Document): The OCR result as a doctr Document object.\n",
        "    Returns:\n",
        "    str: The extracted text content.\n",
        "    \"\"\"\n",
        "    text_content = \"\"\n",
        "    for page in result.pages:\n",
        "        for block in page.blocks:\n",
        "            for line in block.lines:\n",
        "                for word in line.words:\n",
        "                    text_content += word.value + \" \"\n",
        "                text_content += \"\\n\"\n",
        "            text_content += \"\\n\"\n",
        "        text_content += \"\\n\"\n",
        "    return text_content\n",
        "\n",
        "def apply_doctr_model(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Applies the doctr OCR model to images in the input folder and saves the results.\n",
        "    Args:\n",
        "    input_folder (str): Path to the folder containing the input images.\n",
        "    output_folder (str): Path to the folder where the results will be saved.\n",
        "    \"\"\"\n",
        "    image_files = read_images(input_folder)\n",
        "    for image_file in image_files:\n",
        "        result = perform_ocr_doctr(image_file)\n",
        "\n",
        "        # Draw bounding boxes on the image\n",
        "        annotated_image = draw_boxes(image_file, result)\n",
        "\n",
        "        # Save the annotated image\n",
        "        base_name = os.path.splitext(os.path.basename(image_file))[0]\n",
        "        save_image(output_folder, base_name, annotated_image)\n",
        "\n",
        "        # Extract and save text content to a text file\n",
        "        text_content = extract_text(result)\n",
        "        text_file = os.path.join(output_folder, f\"{base_name}.txt\")\n",
        "        with open(text_file, 'w') as f:\n",
        "            f.write(text_content)\n",
        "\n",
        "# Paths\n",
        "input_folder = '/content/In'\n",
        "output_folder = '/content/OCR_Doctr'\n",
        "\n",
        "# Apply the OCR model\n",
        "apply_doctr_model(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "5-itjqzP3LZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}