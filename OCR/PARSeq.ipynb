{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PARSeq: Train a Custom OCR Model**\n",
        "The web content provides a detailed guide on training a custom OCR (Optical Character Recognition) model using PARSeq, particularly for non-English datasets, including steps for repository cloning, charset creation, dataset preparation, and training configuration."
      ],
      "metadata": {
        "id": "ps553_9oEHvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Clone the repository**\n"
      ],
      "metadata": {
        "id": "JtC6NQlpEUPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8f2xbuxD35p",
        "outputId": "56458d74-28c1-4c43-a091-d2abbabe9c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sinhala-ParSeq'...\n",
            "remote: Enumerating objects: 537, done.\u001b[K\n",
            "remote: Counting objects: 100% (537/537), done.\u001b[K\n",
            "remote: Compressing objects: 100% (240/240), done.\u001b[K\n",
            "remote: Total 537 (delta 304), reused 489 (delta 290), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (537/537), 107.56 MiB | 15.18 MiB/s, done.\n",
            "Resolving deltas: 100% (304/304), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dilithjay/Sinhala-ParSeq.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install dependencies**"
      ],
      "metadata": {
        "id": "y0ooIqSKEq_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinstall to resolve undefined character error with torchtext\n",
        "!pip install torch==1.10.0 torchtext==0.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwh2HXlrE0aV",
        "outputId": "10f82217-e5f7-444f-eaf3-8c06c08e4fa8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Sinhala-ParSeq/\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "# Note: May have to restart runtime afterward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xzKeFe5OEbC9",
        "outputId": "6a55b711-c07d-4c2a-d315-c5289d609726"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Sinhala-ParSeq\n",
            "Requirement already satisfied: torch>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.11.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.0+cu121)\n",
            "Collecting pytorch-lightning>=1.6.5 (from -r requirements.txt (line 3))\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting timm~=0.6.5 (from -r requirements.txt (line 4))\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting nltk~=3.7.0 (from -r requirements.txt (line 5))\n",
            "  Downloading nltk-3.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting lmdb~=1.3.0 (from -r requirements.txt (line 6))\n",
            "  Downloading lmdb-1.3.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting Pillow~=9.2.0 (from -r requirements.txt (line 7))\n",
            "  Downloading Pillow-9.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: imgaug~=0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.4.0)\n",
            "Collecting hydra-core~=1.2.0 (from -r requirements.txt (line 9))\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting fvcore~=0.1.5.post20220512 (from -r requirements.txt (line 10))\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ray~=1.13.0 (from ray[tune]~=1.13.0->-r requirements.txt (line 11))\n",
            "  Downloading ray-1.13.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting ax-platform~=0.2.5.1 (from -r requirements.txt (line 12))\n",
            "  Downloading ax_platform-0.2.5.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: PyYAML~=6.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (6.0.2)\n",
            "Collecting tqdm~=4.64.0 (from -r requirements.txt (line 14))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.2->-r requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.2->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.2->-r requirements.txt (line 1)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.2->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.2->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.2->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.11.3->-r requirements.txt (line 2)) (1.26.4)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.6.5->-r requirements.txt (line 3))\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (24.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.6.5->-r requirements.txt (line 3))\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm~=0.6.5->-r requirements.txt (line 4)) (0.24.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7.0->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7.0->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7.0->-r requirements.txt (line 5)) (2024.5.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (0.23.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (4.10.0.84)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (2.34.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug~=0.4.0->-r requirements.txt (line 8)) (2.0.6)\n",
            "Collecting omegaconf~=2.2 (from hydra-core~=1.2.0->-r requirements.txt (line 9))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core~=1.2.0->-r requirements.txt (line 9))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yacs>=0.1.6 (from fvcore~=0.1.5.post20220512->-r requirements.txt (line 10))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore~=0.1.5.post20220512->-r requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore~=0.1.5.post20220512->-r requirements.txt (line 10)) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore~=0.1.5.post20220512->-r requirements.txt (line 10))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (24.2.0)\n",
            "Collecting click (from nltk~=3.7.0->-r requirements.txt (line 5))\n",
            "  Downloading click-8.0.4-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1 (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11))\n",
            "  Downloading grpcio-1.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (1.0.8)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (2.32.3)\n",
            "Collecting virtualenv (from ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11))\n",
            "  Downloading virtualenv-20.26.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting botorch==0.6.4 (from ax-platform~=0.2.5.1->-r requirements.txt (line 12))\n",
            "  Downloading botorch-0.6.4-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (5.15.0)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.10/dist-packages (from ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (4.3.0)\n",
            "Collecting gpytorch>=1.6 (from botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12))\n",
            "  Downloading gpytorch-1.13-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (1.0.0)\n",
            "Collecting pyro-ppl==1.8.0 (from botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12))\n",
            "  Downloading pyro_ppl-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==1.8.0->botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl==1.8.0->botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12))\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]~=1.13.0->-r requirements.txt (line 11))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (3.10.5)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore~=0.1.5.post20220512->-r requirements.txt (line 10))\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (71.0.4)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug~=0.4.0->-r requirements.txt (line 8)) (2024.8.28)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug~=0.4.0->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.2->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (0.20.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug~=0.4.0->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug~=0.4.0->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug~=0.4.0->-r requirements.txt (line 8)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug~=0.4.0->-r requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug~=0.4.0->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug~=0.4.0->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (9.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ax-platform~=0.2.5.1->-r requirements.txt (line 12)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.2->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv->ray~=1.13.0->ray[tune]~=1.13.0->-r requirements.txt (line 11)) (4.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.5->-r requirements.txt (line 3)) (4.0.3)\n",
            "Collecting jaxtyping==0.2.19 (from gpytorch>=1.6->botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12))\n",
            "  Downloading jaxtyping-0.2.19-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting linear-operator>=0.5.3 (from gpytorch>=1.6->botorch==0.6.4->ax-platform~=0.2.5.1->-r requirements.txt (line 12))\n",
            "  Downloading linear_operator-0.5.3-py3-none-any.whl.metadata (15 kB)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.3.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.5/306.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-9.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.1/151.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-1.13.0-cp310-cp310-manylinux2014_x86_64.whl (54.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ax_platform-0.2.5.1-py3-none-any.whl (993 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.9/993.9 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botorch-0.6.4-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.1/363.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.8.0-py3-none-any.whl (713 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.2/713.2 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading virtualenv-20.26.3-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gpytorch-1.13-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.8/277.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.2.19-py3-none-any.whl (24 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading linear_operator-0.5.3-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, fvcore, iopath\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d95ac087c2d531983a34864fc00618fb7b6f1c144a8ca938301886ef559d96cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61395 sha256=477862e9b3dda9041c0f2fa65b8af2714cfcdf5c1c0dce22b2165321d9fede1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=67b8c09e2c79e726cd0cb04f774fad5386aa7a958a30d6da9e2070023ac49c47\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built antlr4-python3-runtime fvcore iopath\n",
            "Installing collected packages: pyro-api, lmdb, distlib, antlr4-python3-runtime, yacs, virtualenv, tqdm, tensorboardX, portalocker, Pillow, omegaconf, lightning-utilities, grpcio, click, nltk, jaxtyping, iopath, hydra-core, torchmetrics, pyro-ppl, linear-operator, fvcore, timm, ray, pytorch-lightning, gpytorch, botorch, ax-platform\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.64.1\n",
            "    Uninstalling grpcio-1.64.1:\n",
            "      Successfully uninstalled grpcio-1.64.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.7.1 requires click>=8.1, but you have click 8.0.4 which is incompatible.\n",
            "google-cloud-pubsub 2.23.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.43.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires grpcio<2.0.0dev,>=1.44.0, but you have grpcio 1.43.0 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.43.0 which is incompatible.\n",
            "tensorboard 2.17.0 requires grpcio>=1.48.2, but you have grpcio 1.43.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 antlr4-python3-runtime-4.9.3 ax-platform-0.2.5.1 botorch-0.6.4 click-8.0.4 distlib-0.3.8 fvcore-0.1.5.post20221221 gpytorch-1.13 grpcio-1.43.0 hydra-core-1.2.0 iopath-0.1.10 jaxtyping-0.2.19 lightning-utilities-0.11.7 linear-operator-0.5.3 lmdb-1.3.0 nltk-3.7 omegaconf-2.3.0 portalocker-2.10.1 pyro-api-0.1.2 pyro-ppl-1.8.0 pytorch-lightning-2.4.0 ray-1.13.0 tensorboardX-2.6.2.2 timm-0.6.13 torchmetrics-1.4.1 tqdm-4.64.1 virtualenv-20.26.3 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              },
              "id": "b0ef70a196de4e68af130b15cc75135e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/Sinhala-ParSeq\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of strhub to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch~=1.10.2 (from strhub) (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch~=1.10.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y7fv9E_UG8Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create the dataset, the PARSeq repo provides an updated version of a python script that’s generally used for this purpose. Therefore, you can find the script here or inside the tools directory within the repo you cloned.\n",
        "\n",
        "Before running the script, you will need the following:\n",
        "\n",
        "A place to store the .lmdb file. One thing to note is that the drive you're saving to should have sufficient space. If you don't have about 1TB of free space in your drive. Change the map_size attribute of lmdb.open() from 1099511627776 to 1073741824.\n",
        "A directory with all the training images. Make sure the names of the images do not have spaces.\n",
        "A text file with all the image names and their respective text. So for example, the content of the text file may look something like this:\n",
        "\n",
        "img_1.jpg hello\n",
        "\n",
        "img_2.jpg world\n",
        "\n",
        "img_3.jpg someword\n",
        "\n",
        "\n",
        "# **Create the dataset yaml file**\n",
        "Similar to charset, there’s also a dataset directory inside the configs directory. Accordingly, create a yaml file with the name of your dataset. You can simply duplicate one of the existing files and rename the yaml file's name and the train_dir attribute to the name of your dataset. The train_dir doesn't have to be the same name as your dataset, but it's easier this way. In my case, the name of my dataset is sin_hw, so the content of the sin_hw.yaml file is the following.\n",
        "\n",
        "data: train_dir: sin_hw num_workers: 2\n",
        "\n"
      ],
      "metadata": {
        "id": "KLCrSFo2G83i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train**\n",
        "\n",
        "running the following command should start the training process:"
      ],
      "metadata": {
        "id": "4ZGUmI0nEvW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%cd /content/Sinhala-ParSeq/\n",
        "!python train.py"
      ],
      "metadata": {
        "id": "UyXt05CAEul8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bKqP3VkTHell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **evaluation**"
      ],
      "metadata": {
        "id": "AIlJFnOFFGXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Sinhala-ParSeq/\n",
        "from strhub.data.module import SceneTextDataModule\n",
        "\n",
        "# Be sure to change the following as needed (or as specified in the config files)\n",
        "root_dir = 'data'\n",
        "train_dir = 'sin_printed'\n",
        "batch_size = 8\n",
        "img_size = [ 32, 128 ]\n",
        "charset_train = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ01\"\n",
        "charset_test = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ01\"\n",
        "max_label_length = 25\n",
        "augment = False\n",
        "num_workers = 2\n",
        "\n",
        "datamodule = SceneTextDataModule(root_dir, train_dir, img_size, max_label_length,\n",
        "                 charset_train, charset_test, batch_size, num_workers, augment)\n",
        "\n",
        "\n",
        "%cd /content/Sinhala-ParSeq/\n",
        "from strhub.models.utils import load_from_checkpoint\n",
        "from glob import glob\n",
        "\n",
        "# Load the latest model\n",
        "checkpoints = glob('/content/Sinhala-ParSeq/outputs/parseq/*/checkpoints/last.ckpt')\n",
        "\n",
        "checkpoint_path = sorted(checkpoints)[-1]\n",
        "print(checkpoint_path)\n",
        "model = load_from_checkpoint(checkpoint_path, charset_test=charset_test).eval().to('cuda')\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataloader = datamodule.val_dataloader()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "ned = 0\n",
        "confidence = 0\n",
        "label_length = 0\n",
        "for imgs, labels in tqdm(iter(dataloader)):\n",
        "    res = model.test_step((imgs.to(model.device), labels), -1)['output']\n",
        "    total += res.num_samples\n",
        "    correct += res.correct\n",
        "    ned += res.ned\n",
        "    confidence += res.confidence\n",
        "    label_length += res.label_length\n",
        "accuracy = 100 * correct / total\n",
        "mean_ned = 100 * (1 - ned / total)\n",
        "mean_conf = 100 * confidence / total\n",
        "mean_label_length = label_length / total\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy}, Mean ned: {mean_ned}, Mean confidence: {mean_conf}, Mean label length: {mean_label_length}\")\n",
        "\n",
        "\n",
        "# Take a look at the images produced by the dataloader\n",
        "import torchvision.transforms as T\n",
        "transform = T.ToPILImage()\n",
        "for images, labels in datamodule.val_dataloader():\n",
        "  print(model.test_step((imgs.to(model.device), labels), -1)['output'])\n",
        "  for i, img in enumerate(images):\n",
        "    display(transform(img))\n",
        "    print(labels[i])\n",
        "\n",
        "  break\n",
        "\n"
      ],
      "metadata": {
        "id": "GODNXmqFEbFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2FIa_oeEbHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jSUbSxEEbJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdPpDpC4EbMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}