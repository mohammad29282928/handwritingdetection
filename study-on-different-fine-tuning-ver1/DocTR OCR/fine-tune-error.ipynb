{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EQMXNTX9mY8",
        "outputId": "18354e47-ff33-4dba-ba14-e329e91406ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'doctr'...\n",
            "remote: Enumerating objects: 63516, done.\u001b[K\n",
            "remote: Counting objects: 100% (10654/10654), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2267/2267), done.\u001b[K\n",
            "remote: Total 63516 (delta 7707), reused 10223 (delta 7399), pack-reused 52862\u001b[K\n",
            "Receiving objects: 100% (63516/63516), 79.40 MiB | 20.70 MiB/s, done.\n",
            "Resolving deltas: 100% (45075/45075), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mindee/doctr.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVPapxVIAxEX",
        "outputId": "f2be9afd-1368-4bba-80d5-328c7150b71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python lmdb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLF_Bm87ChQW",
        "outputId": "57909380-f51e-4cdb-cba0-d645aa2ae248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16hKdCSCeCAzV7SMVGxIx9hmchavW5lBw\n",
            "To: /content/images.zip\n",
            "100% 4.53M/4.53M [00:00<00:00, 32.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 16hKdCSCeCAzV7SMVGxIx9hmchavW5lBw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUFO0fSKChzq",
        "outputId": "afbdc064-e4f1-4528-f795-245e865ed60b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  images.zip\n",
            "   creating: images/\n",
            "  inflating: images/88.png           \n",
            "  inflating: __MACOSX/images/._88.png  \n",
            "  inflating: images/77.png           \n",
            "  inflating: __MACOSX/images/._77.png  \n",
            "  inflating: images/63.png           \n",
            "  inflating: __MACOSX/images/._63.png  \n",
            "  inflating: images/62.png           \n",
            "  inflating: __MACOSX/images/._62.png  \n",
            "  inflating: images/76.png           \n",
            "  inflating: __MACOSX/images/._76.png  \n",
            "  inflating: images/89.png           \n",
            "  inflating: __MACOSX/images/._89.png  \n",
            "  inflating: images/48.jpg           \n",
            "  inflating: __MACOSX/images/._48.jpg  \n",
            "  inflating: images/60.png           \n",
            "  inflating: __MACOSX/images/._60.png  \n",
            "  inflating: images/74.png           \n",
            "  inflating: __MACOSX/images/._74.png  \n",
            "  inflating: images/75.png           \n",
            "  inflating: __MACOSX/images/._75.png  \n",
            "  inflating: images/61.png           \n",
            "  inflating: __MACOSX/images/._61.png  \n",
            "  inflating: images/49.jpg           \n",
            "  inflating: __MACOSX/images/._49.jpg  \n",
            "  inflating: images/59.png           \n",
            "  inflating: __MACOSX/images/._59.png  \n",
            "  inflating: images/65.png           \n",
            "  inflating: __MACOSX/images/._65.png  \n",
            "  inflating: images/71.png           \n",
            "  inflating: __MACOSX/images/._71.png  \n",
            "  inflating: images/70.png           \n",
            "  inflating: __MACOSX/images/._70.png  \n",
            "  inflating: images/64.png           \n",
            "  inflating: __MACOSX/images/._64.png  \n",
            "  inflating: images/58.png           \n",
            "  inflating: __MACOSX/images/._58.png  \n",
            "  inflating: images/99.png           \n",
            "  inflating: __MACOSX/images/._99.png  \n",
            "  inflating: images/8.png            \n",
            "  inflating: __MACOSX/images/._8.png  \n",
            "  inflating: images/72.png           \n",
            "  inflating: __MACOSX/images/._72.png  \n",
            "  inflating: images/66.png           \n",
            "  inflating: __MACOSX/images/._66.png  \n",
            "  inflating: images/67.png           \n",
            "  inflating: __MACOSX/images/._67.png  \n",
            "  inflating: images/73.png           \n",
            "  inflating: __MACOSX/images/._73.png  \n",
            "  inflating: images/9.png            \n",
            "  inflating: __MACOSX/images/._9.png  \n",
            "  inflating: images/98.png           \n",
            "  inflating: __MACOSX/images/._98.png  \n",
            "  inflating: images/14.jpg           \n",
            "  inflating: __MACOSX/images/._14.jpg  \n",
            "  inflating: images/28.jpg           \n",
            "  inflating: __MACOSX/images/._28.jpg  \n",
            "  inflating: images/101.png          \n",
            "  inflating: __MACOSX/images/._101.png  \n",
            "  inflating: images/100.png          \n",
            "  inflating: __MACOSX/images/._100.png  \n",
            "  inflating: images/29.jpg           \n",
            "  inflating: __MACOSX/images/._29.jpg  \n",
            "  inflating: images/15.jpg           \n",
            "  inflating: __MACOSX/images/._15.jpg  \n",
            "  inflating: images/17.jpg           \n",
            "  inflating: __MACOSX/images/._17.jpg  \n",
            "  inflating: images/102.png          \n",
            "  inflating: __MACOSX/images/._102.png  \n",
            "  inflating: images/103.png          \n",
            "  inflating: __MACOSX/images/._103.png  \n",
            "  inflating: images/16.jpg           \n",
            "  inflating: __MACOSX/images/._16.jpg  \n",
            "  inflating: images/107.png          \n",
            "  inflating: __MACOSX/images/._107.png  \n",
            "  inflating: images/12.png           \n",
            "  inflating: __MACOSX/images/._12.png  \n",
            "  inflating: images/13.png           \n",
            "  inflating: __MACOSX/images/._13.png  \n",
            "  inflating: images/106.png          \n",
            "  inflating: __MACOSX/images/._106.png  \n",
            "  inflating: images/39.jpg           \n",
            "  inflating: __MACOSX/images/._39.jpg  \n",
            "  inflating: images/110.png          \n",
            "  inflating: __MACOSX/images/._110.png  \n",
            "  inflating: images/104.png          \n",
            "  inflating: __MACOSX/images/._104.png  \n",
            "  inflating: images/11.png           \n",
            "  inflating: __MACOSX/images/._11.png  \n",
            "  inflating: images/10.png           \n",
            "  inflating: __MACOSX/images/._10.png  \n",
            "  inflating: images/105.png          \n",
            "  inflating: __MACOSX/images/._105.png  \n",
            "  inflating: images/111.png          \n",
            "  inflating: __MACOSX/images/._111.png  \n",
            "  inflating: images/38.jpg           \n",
            "  inflating: __MACOSX/images/._38.jpg  \n",
            "  inflating: images/21.jpg           \n",
            "  inflating: __MACOSX/images/._21.jpg  \n",
            "  inflating: images/35.jpg           \n",
            "  inflating: __MACOSX/images/._35.jpg  \n",
            "  inflating: images/108.png          \n",
            "  inflating: __MACOSX/images/._108.png  \n",
            "  inflating: images/109.png          \n",
            "  inflating: __MACOSX/images/._109.png  \n",
            "  inflating: images/34.jpg           \n",
            "  inflating: __MACOSX/images/._34.jpg  \n",
            "  inflating: images/20.jpg           \n",
            "  inflating: __MACOSX/images/._20.jpg  \n",
            "  inflating: images/36.jpg           \n",
            "  inflating: __MACOSX/images/._36.jpg  \n",
            "  inflating: images/22.jpg           \n",
            "  inflating: __MACOSX/images/._22.jpg  \n",
            "  inflating: images/23.jpg           \n",
            "  inflating: __MACOSX/images/._23.jpg  \n",
            "  inflating: images/37.jpg           \n",
            "  inflating: __MACOSX/images/._37.jpg  \n",
            "  inflating: images/33.jpg           \n",
            "  inflating: __MACOSX/images/._33.jpg  \n",
            "  inflating: images/27.jpg           \n",
            "  inflating: __MACOSX/images/._27.jpg  \n",
            "  inflating: images/111.ipynb        \n",
            "  inflating: __MACOSX/images/._111.ipynb  \n",
            "  inflating: images/26.jpg           \n",
            "  inflating: __MACOSX/images/._26.jpg  \n",
            "  inflating: images/32.jpg           \n",
            "  inflating: __MACOSX/images/._32.jpg  \n",
            "  inflating: images/18.jpg           \n",
            "  inflating: __MACOSX/images/._18.jpg  \n",
            "  inflating: images/24.jpg           \n",
            "  inflating: __MACOSX/images/._24.jpg  \n",
            "  inflating: images/30.jpg           \n",
            "  inflating: __MACOSX/images/._30.jpg  \n",
            "  inflating: images/31.jpg           \n",
            "  inflating: __MACOSX/images/._31.jpg  \n",
            "  inflating: images/25.jpg           \n",
            "  inflating: __MACOSX/images/._25.jpg  \n",
            "  inflating: images/19.jpg           \n",
            "  inflating: __MACOSX/images/._19.jpg  \n",
            "  inflating: images/42.jpg           \n",
            "  inflating: __MACOSX/images/._42.jpg  \n",
            "  inflating: images/95.png           \n",
            "  inflating: __MACOSX/images/._95.png  \n",
            "  inflating: images/81.png           \n",
            "  inflating: __MACOSX/images/._81.png  \n",
            "  inflating: images/4.png            \n",
            "  inflating: __MACOSX/images/._4.png  \n",
            "  inflating: images/56.png           \n",
            "  inflating: __MACOSX/images/._56.png  \n",
            "  inflating: images/5.png            \n",
            "  inflating: __MACOSX/images/._5.png  \n",
            "  inflating: images/57.png           \n",
            "  inflating: __MACOSX/images/._57.png  \n",
            "  inflating: images/80.png           \n",
            "  inflating: __MACOSX/images/._80.png  \n",
            "  inflating: images/94.png           \n",
            "  inflating: __MACOSX/images/._94.png  \n",
            "  inflating: images/43.jpg           \n",
            "  inflating: __MACOSX/images/._43.jpg  \n",
            "  inflating: images/41.jpg           \n",
            "  inflating: __MACOSX/images/._41.jpg  \n",
            "  inflating: images/82.png           \n",
            "  inflating: __MACOSX/images/._82.png  \n",
            "  inflating: images/96.png           \n",
            "  inflating: __MACOSX/images/._96.png  \n",
            "  inflating: images/55.png           \n",
            "  inflating: __MACOSX/images/._55.png  \n",
            "  inflating: images/7.png            \n",
            "  inflating: __MACOSX/images/._7.png  \n",
            "  inflating: images/69.png           \n",
            "  inflating: __MACOSX/images/._69.png  \n",
            "  inflating: images/68.png           \n",
            "  inflating: __MACOSX/images/._68.png  \n",
            "  inflating: images/54.png           \n",
            "  inflating: __MACOSX/images/._54.png  \n",
            "  inflating: images/6.png            \n",
            "  inflating: __MACOSX/images/._6.png  \n",
            "  inflating: images/97.png           \n",
            "  inflating: __MACOSX/images/._97.png  \n",
            "  inflating: images/83.png           \n",
            "  inflating: __MACOSX/images/._83.png  \n",
            "  inflating: images/40.jpg           \n",
            "  inflating: __MACOSX/images/._40.jpg  \n",
            "  inflating: images/50.jpg           \n",
            "  inflating: __MACOSX/images/._50.jpg  \n",
            "  inflating: images/44.jpg           \n",
            "  inflating: __MACOSX/images/._44.jpg  \n",
            "  inflating: images/87.png           \n",
            "  inflating: __MACOSX/images/._87.png  \n",
            "  inflating: images/93.png           \n",
            "  inflating: __MACOSX/images/._93.png  \n",
            "  inflating: images/78.png           \n",
            "  inflating: __MACOSX/images/._78.png  \n",
            "  inflating: images/2.png            \n",
            "  inflating: __MACOSX/images/._2.png  \n",
            "  inflating: images/3.png            \n",
            "  inflating: __MACOSX/images/._3.png  \n",
            "  inflating: images/51.png           \n",
            "  inflating: __MACOSX/images/._51.png  \n",
            "  inflating: images/79.png           \n",
            "  inflating: __MACOSX/images/._79.png  \n",
            "  inflating: images/92.png           \n",
            "  inflating: __MACOSX/images/._92.png  \n",
            "  inflating: images/86.png           \n",
            "  inflating: __MACOSX/images/._86.png  \n",
            "  inflating: images/45.jpg           \n",
            "  inflating: __MACOSX/images/._45.jpg  \n",
            "  inflating: images/47.jpg           \n",
            "  inflating: __MACOSX/images/._47.jpg  \n",
            "  inflating: images/90.png           \n",
            "  inflating: __MACOSX/images/._90.png  \n",
            "  inflating: images/84.png           \n",
            "  inflating: __MACOSX/images/._84.png  \n",
            "  inflating: images/53.png           \n",
            "  inflating: __MACOSX/images/._53.png  \n",
            "  inflating: images/1.png            \n",
            "  inflating: __MACOSX/images/._1.png  \n",
            "  inflating: images/52.png           \n",
            "  inflating: __MACOSX/images/._52.png  \n",
            "  inflating: images/85.png           \n",
            "  inflating: __MACOSX/images/._85.png  \n",
            "  inflating: images/91.png           \n",
            "  inflating: __MACOSX/images/._91.png  \n",
            "  inflating: images/46.jpg           \n",
            "  inflating: __MACOSX/images/._46.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4gItSHcCFQs",
        "outputId": "b7d74938-dd07-460a-b16e-63b2e2294a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done creating LMDB at /content/val\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import lmdb\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def read_text_file(txt_file_path):\n",
        "    data = []\n",
        "    with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            image_path, text = line.strip().split('\\t')\n",
        "            data.append((image_path, text))\n",
        "    return data\n",
        "\n",
        "def write_to_lmdb(data, lmdb_path, map_size=1e12):\n",
        "    env = lmdb.open(lmdb_path, map_size=int(map_size))\n",
        "    with env.begin(write=True) as txn:\n",
        "        for idx, (image_path, text) in enumerate(data):\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                print(f\"Error reading image {image_path}\")\n",
        "                continue\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            ext = os.path.splitext(image_path)[-1].lower()\n",
        "            if ext in ['.jpg', '.jpeg']:\n",
        "                image_bin = cv2.imencode('.jpg', image)[1].tobytes()\n",
        "            elif ext == '.png':\n",
        "                image_bin = cv2.imencode('.png', image)[1].tobytes()\n",
        "            else:\n",
        "                print(f\"Unsupported image format {image_path}\")\n",
        "                continue\n",
        "\n",
        "            str_id = str(idx).zfill(8)\n",
        "            txn.put(str_id.encode(), image_bin)\n",
        "            txn.put(f'{str_id}_label'.encode(), text.encode())\n",
        "\n",
        "def main():\n",
        "    txt_file_path = '/content/val/output_label.txt'\n",
        "    lmdb_path = '/content/val'\n",
        "    data = read_text_file(txt_file_path)\n",
        "    write_to_lmdb(data, lmdb_path)\n",
        "    print(f'Done creating LMDB at {lmdb_path}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha3MLORzDMvJ",
        "outputId": "fe4a3caa-452e-49f7-c9ef-90170cb6a4ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-doctr\n",
            "  Downloading python_doctr-0.8.1-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from python-doctr) (8.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (1.26.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (1.13.1)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (3.11.0)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (4.10.0.84)\n",
            "Collecting pypdfium2<5.0.0,>=4.0.0 (from python-doctr)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyclipper<2.0.0,>=1.2.0 (from python-doctr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: shapely<3.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (2.0.5)\n",
            "Collecting langdetect<2.0.0,>=1.0.9 (from python-doctr)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from python-doctr)\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (0.23.5)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (3.7.1)\n",
            "Collecting weasyprint>=55.0 (from python-doctr)\n",
            "  Downloading weasyprint-62.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: Pillow>=9.2.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (9.4.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (0.7.1)\n",
            "Collecting mplcursors>=0.3 (from python-doctr)\n",
            "  Downloading mplcursors-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.0.0 (from python-doctr)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from python-doctr) (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.20.0->python-doctr) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect<2.0.0,>=1.0.9->python-doctr) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->python-doctr) (2.8.2)\n",
            "Collecting matplotlib>=3.1.0 (from python-doctr)\n",
            "  Downloading matplotlib-3.9.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pydyf>=0.10.0 (from weasyprint>=55.0->python-doctr)\n",
            "  Downloading pydyf-0.11.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from weasyprint>=55.0->python-doctr) (1.16.0)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint>=55.0->python-doctr) (1.1)\n",
            "Requirement already satisfied: tinycss2>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint>=55.0->python-doctr) (1.3.0)\n",
            "Collecting cssselect2>=0.1 (from weasyprint>=55.0->python-doctr)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting Pyphen>=0.9.1 (from weasyprint>=55.0->python-doctr)\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->python-doctr) (3.19.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->weasyprint>=55.0->python-doctr) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.1->weasyprint>=55.0->python-doctr) (0.5.1)\n",
            "Collecting zopfli>=0.1.4 (from fonttools[woff]>=4.0.0->weasyprint>=55.0->python-doctr)\n",
            "  Downloading zopfli-0.2.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting brotli>=1.0.1 (from fonttools[woff]>=4.0.0->weasyprint>=55.0->python-doctr)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.20.0->python-doctr) (2024.7.4)\n",
            "Downloading python_doctr-0.8.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading weasyprint-62.3-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Downloading pydyf-0.11.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zopfli-0.2.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (848 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m848.9/848.9 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, mplcursors\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=8d78a3abd6863741cb75392068f6d05ed85f65df70f0bcca21ca20efb71ee5d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for mplcursors (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mplcursors: filename=mplcursors-0.5.3-py3-none-any.whl size=20727 sha256=b757f7baef305cc9dc05d778a8bc9bf867bbfb195b905f6dc750e1ae89b3dbaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/43/92/44f9515471f56877c774a515a2902d3e5484ea1bc7fd412d03\n",
            "Successfully built langdetect mplcursors\n",
            "Installing collected packages: pyclipper, brotli, zopfli, unidecode, rapidfuzz, Pyphen, pypdfium2, pydyf, langdetect, matplotlib, cssselect2, weasyprint, mplcursors, python-doctr\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "Successfully installed Pyphen-0.16.0 brotli-1.1.0 cssselect2-0.7.0 langdetect-1.0.9 matplotlib-3.9.1.post1 mplcursors-0.5.3 pyclipper-1.3.0.post5 pydyf-0.11.0 pypdfium2-4.30.0 python-doctr-0.8.1 rapidfuzz-3.9.6 unidecode-1.3.8 weasyprint-62.3 zopfli-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install python-doctr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x1cH3WWDqBt",
        "outputId": "95b3106f-1788-44e1-ee09-95785b7f6393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.7.4)\n",
            "Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, tf2onnx\n",
            "Successfully installed onnx-1.16.2 tf2onnx-1.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jDCBYYNRRv1",
        "outputId": "1da0bc55-0ea5-4c56-9191-03504d9766b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted /content/val/output_label.txt to /content/val/labels.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def txt_to_json(txt_file, json_file):\n",
        "    data = {}\n",
        "\n",
        "    with open(txt_file, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            # Split the line into image path and text\n",
        "            image_path, text = line.strip().split('\\t')\n",
        "            # Use the image filename as the key\n",
        "            filename = os.path.basename(image_path)\n",
        "            data[filename] = text\n",
        "\n",
        "    with open(json_file, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Specify the path to your txt file and the desired output path for the json file\n",
        "txt_file = '/content/val/output_label.txt'\n",
        "json_file = '/content/val/labels.json'\n",
        "\n",
        "txt_to_json(txt_file, json_file)\n",
        "\n",
        "print(f\"Converted {txt_file} to {json_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YixuopQU0NW",
        "outputId": "65ae6a27-3e3a-42b4-a346-60b924856484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__path__', '__file__', '__cached__', '__builtins__', 'core', 'crnn', 'is_tf_available', 'is_torch_available', 'tensorflow', 'CRNN', 'crnn_vgg16_bn', 'crnn_mobilenet_v3_small', 'crnn_mobilenet_v3_large', 'master', 'base', 'MASTER', 'sar', 'SAR', 'sar_resnet31', 'vitstr', 'ViTSTR', 'vitstr_small', 'vitstr_base', 'parseq', 'PARSeq', 'utils', 'predictor', 'zoo', 'recognition_predictor'])\n"
          ]
        }
      ],
      "source": [
        "# Assuming doctr library provides a function to list available architectures\n",
        "import doctr\n",
        "print(doctr.models.recognition.__dict__.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ‘‡ error part: we creat two different folders for train and validation set of data set then creat a image folder in each of them and we have converted csv manifest file into json format which required by DocTR model , after prepraing dataset we run command below for training model , but it couldn't read pretrained whieghts from colab , because of Keras version confliction !\n",
        "####  i got this error :\n",
        "#### ğŸ‘‡  Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE9LpqDNSR22",
        "outputId": "998d34d5-30d7-4279-aea5-f16fb0743700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-07 10:21:29.366530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-07 10:21:29.399339: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-07 10:21:29.407703: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Namespace(arch='parseq', train_path='/content/train', val_path='/content/val', train_samples=1000, val_samples=20, font='FreeMono.ttf,FreeSans.ttf,FreeSerif.ttf', min_chars=1, max_chars=12, name=None, epochs=20, batch_size=32, input_size=32, lr=0.001, resume=None, vocab='english', test_only=False, freeze_backbone=False, show_samples=False, wb=False, clearml=False, push_to_hub=False, pretrained=True, amp=False, find_lr=False, early_stop=True, early_stop_epochs=5, early_stop_delta=0.01)\n",
            "Validation set loaded in 0.0003743s (16 samples in 1 batches)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/doctr/references/recognition/train_tensorflow.py\", line 441, in <module>\n",
            "    main(args)\n",
            "  File \"/content/doctr/references/recognition/train_tensorflow.py\", line 180, in main\n",
            "    model = recognition.__dict__[args.arch](\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/models/recognition/parseq/tensorflow.py\", line 504, in parseq\n",
            "    return _parseq(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/models/recognition/parseq/tensorflow.py\", line 480, in _parseq\n",
            "    load_pretrained_params(model, default_cfgs[arch][\"url\"])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/models/utils/tensorflow.py\", line 73, in load_pretrained_params\n",
            "    model.load_weights(f\"{params_path}{os.sep}{internal_name}\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\", line 268, in load_weights\n",
            "    raise ValueError(\n",
            "ValueError: File format not supported: filepath=/root/.cache/doctr/models/parseq-24cf693e/weights. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.\n"
          ]
        }
      ],
      "source": [
        "!python /content/doctr/references/recognition/train_tensorflow.py parseq --train_path /content/train --val_path /content/val --epochs 20 --batch_size 32 --input_size 32 --lr 0.001 --vocab english --pretrained --early-stop --early-stop-epochs 5 --early-stop-delta 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnW-q4RMXX6z",
        "outputId": "cc66358c-0830-405d-af64-c5a3b8391db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-07 10:23:35.218302: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-07 10:23:35.260064: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-07 10:23:35.271380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "usage: train_tensorflow.py [-h] [--train_path TRAIN_PATH] [--val_path VAL_PATH]\n",
            "                           [--train-samples TRAIN_SAMPLES] [--val-samples VAL_SAMPLES]\n",
            "                           [--font FONT] [--min-chars MIN_CHARS] [--max-chars MAX_CHARS]\n",
            "                           [--name NAME] [--epochs EPOCHS] [-b BATCH_SIZE]\n",
            "                           [--input_size INPUT_SIZE] [--lr LR] [--resume RESUME] [--vocab VOCAB]\n",
            "                           [--test-only] [--freeze-backbone] [--show-samples] [--wb] [--clearml]\n",
            "                           [--push-to-hub] [--pretrained] [--amp] [--find-lr] [--early-stop]\n",
            "                           [--early-stop-epochs EARLY_STOP_EPOCHS]\n",
            "                           [--early-stop-delta EARLY_STOP_DELTA]\n",
            "                           arch\n",
            "train_tensorflow.py: error: the following arguments are required: arch\n"
          ]
        }
      ],
      "source": [
        "!python /content/doctr/references/recognition/train_tensorflow.py --arch=\"parseq\" --train_path /content/train --val_path /content/val --epochs 20 --batch_size 32 --input_size 32 --lr 0.001 --vocab english --pretrained --early-stop --early-stop-epochs 5 --early-stop-delta 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45CDsfuYkvbx",
        "outputId": "3a7078ae-3bf4-47d8-883c-afe583db42de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras==3.4.1\n",
            "  Using cached keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras==3.4.1) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.2)\n",
            "Using cached keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "Successfully installed keras-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install keras==3.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvJ8PEi8Xrna",
        "outputId": "e95fa544-0112-46ae-f2ac-cced78d7d615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-07 12:02:52.904173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-07 12:02:52.929263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-07 12:02:52.936659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Namespace(arch='crnn_vgg16_bn', train_path='/content/train', val_path='/content/val', train_samples=1000, val_samples=20, font='FreeMono.ttf,FreeSans.ttf,FreeSerif.ttf', min_chars=1, max_chars=12, name=None, epochs=20, batch_size=32, input_size=32, lr=0.001, resume=None, vocab='english', test_only=False, freeze_backbone=False, show_samples=False, wb=False, clearml=False, push_to_hub=False, pretrained=True, amp=False, find_lr=False, early_stop=True, early_stop_epochs=5, early_stop_delta=0.01)\n",
            "Validation set loaded in 0.0003996s (16 samples in 1 batches)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/doctr/references/recognition/train_tensorflow.py\", line 441, in <module>\n",
            "    main(args)\n",
            "  File \"/content/doctr/references/recognition/train_tensorflow.py\", line 180, in main\n",
            "    model = recognition.__dict__[args.arch](\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/models/recognition/crnn/tensorflow.py\", line 274, in crnn_vgg16_bn\n",
            "    return _crnn(\"crnn_vgg16_bn\", pretrained, vgg16_bn_r, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/models/recognition/crnn/tensorflow.py\", line 250, in _crnn\n",
            "    load_pretrained_params(model, _cfg[\"url\"])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/models/utils/tensorflow.py\", line 73, in load_pretrained_params\n",
            "    model.load_weights(f\"{params_path}{os.sep}{internal_name}\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\", line 268, in load_weights\n",
            "    raise ValueError(\n",
            "ValueError: File format not supported: filepath=/root/.cache/doctr/models/crnn_vgg16_bn-76b7f2c6/weights. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.\n"
          ]
        }
      ],
      "source": [
        "!python /content/doctr/references/recognition/train_tensorflow.py crnn_vgg16_bn --train_path /content/train --val_path /content/val --epochs 20 --batch_size 32 --input_size 32 --lr 0.001 --vocab english --pretrained --early-stop --early-stop-epochs 5 --early-stop-delta 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_0a5cUVWEcr",
        "outputId": "8db82b65-6a9d-4a25-950d-b5a6a5a03c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-07 10:19:40.808615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-07 10:19:40.837275: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-07 10:19:40.853551: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "usage: train_tensorflow.py [-h] [--train_path TRAIN_PATH] [--val_path VAL_PATH]\n",
            "                           [--train-samples TRAIN_SAMPLES] [--val-samples VAL_SAMPLES]\n",
            "                           [--font FONT] [--min-chars MIN_CHARS] [--max-chars MAX_CHARS]\n",
            "                           [--name NAME] [--epochs EPOCHS] [-b BATCH_SIZE]\n",
            "                           [--input_size INPUT_SIZE] [--lr LR] [--resume RESUME] [--vocab VOCAB]\n",
            "                           [--test-only] [--freeze-backbone] [--show-samples] [--wb] [--clearml]\n",
            "                           [--push-to-hub] [--pretrained] [--amp] [--find-lr] [--early-stop]\n",
            "                           [--early-stop-epochs EARLY_STOP_EPOCHS]\n",
            "                           [--early-stop-delta EARLY_STOP_DELTA]\n",
            "                           arch\n",
            "train_tensorflow.py: error: the following arguments are required: arch\n"
          ]
        }
      ],
      "source": [
        "!python /content/doctr/references/recognition/train_tensorflow.py --arch=\"parseq\" --train_path /content/train --val_path /content/val --epochs 20 --batch_size 32 --input_size 32 --lr 0.001 --vocab english --pretrained --early-stop --early-stop-epochs 5 --early-stop-delta 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ux1BNwd-DMC",
        "outputId": "33f3f5ed-8c22-432d-eb7d-c4482e066327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-07 09:57:59.667646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-07 09:57:59.692005: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-07 09:57:59.699162: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Namespace(arch='recognition_model', train_path='/content/train', val_path='/content/val', train_samples=1000, val_samples=20, font='FreeMono.ttf,FreeSans.ttf,FreeSerif.ttf', min_chars=1, max_chars=12, name=None, epochs=20, batch_size=32, input_size=32, lr=0.001, resume=None, vocab='english', test_only=False, freeze_backbone=False, show_samples=False, wb=False, clearml=False, push_to_hub=False, pretrained=True, amp=False, find_lr=False, early_stop=True, early_stop_epochs=5, early_stop_delta=0.01)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/doctr/references/recognition/train_tensorflow.py\", line 441, in <module>\n",
            "    main(args)\n",
            "  File \"/content/doctr/references/recognition/train_tensorflow.py\", line 147, in main\n",
            "    val_set = RecognitionDataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/datasets/recognition.py\", line 37, in __init__\n",
            "    super().__init__(img_folder, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/doctr/datasets/datasets/base.py\", line 33, in __init__\n",
            "    raise ValueError(f\"expected a path to a reachable folder: {root}\")\n",
            "ValueError: expected a path to a reachable folder: /content/val/images\n"
          ]
        }
      ],
      "source": [
        "!python /content/doctr/references/recognition/train_tensorflow.py recognition_model \\\n",
        "  --train_path \"/content/train\" \\\n",
        "  --val_path \"/content/val\" \\\n",
        "  --vocab \"english\" \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 32 \\\n",
        "  --input_size 32 \\\n",
        "  --lr 0.001 \\\n",
        "  --pretrained \\\n",
        "  --early-stop \\\n",
        "  --early-stop-epochs 5 \\\n",
        "  --early-stop-delta 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBCKUnwv-Elu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
